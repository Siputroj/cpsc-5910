{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac77aa7",
   "metadata": {},
   "source": [
    "# PART 1: The Memory Path\n",
    "\n",
    "|Configuration|KV heads|Memory usage (MB)|Reduction Factor|\n",
    "|-----------|-----------|-----------|-----------|\n",
    "|MHA|32|1 batch * 32 heads * 128 head dimension * 4096 tokens * 2 bytes per element * 2 for K and V = 67,108,864 bytes = 67.1MB|1x|\n",
    "|MQA|1|1 batch * 1 head * 128 head dimensions * 4096 tokens * 2 byte per element * 2 for K and V = 2,097,152 bytes = 2.1MB|32x|\n",
    "|GQA|8|1 batch * 8 head * 128 head dimensions * 4096 tokens * 2 byte per element * 2 for K and V = 16,777,216 bytes = 16.8MB|4x|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861c68ac",
   "metadata": {},
   "source": [
    "# PART 2: the `repeat_kv` Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b86ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def repeat_kv(x: torch.Tensor, num_repeats: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Repeats the KV heads to match the number of query heads.\n",
    "    \n",
    "    Args:\n",
    "        x: Tensor of shape (B, n_kv_heads, T, head_dim)\n",
    "        num_repeats: How many times to repeat each KV head\n",
    "        \n",
    "    Returns:\n",
    "        Tensor of shape (B, n_kv_heads * num_repeats, T, head_dim)\n",
    "    \"\"\"\n",
    "    if num_repeats == 1:\n",
    "        return x\n",
    "    \n",
    "    # Use repeat_interleave on the head dimension (dim=1)\n",
    "    # This repeats each head 'num_repeats' times: [H1, H1, H2, H2...]\n",
    "    return x.repeat_interleave(num_repeats, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dae5cdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  [1, 2, 4, 8]\n",
      "Num repeats:  2\n",
      "Output shape: [1, 4, 4, 8]\n"
     ]
    }
   ],
   "source": [
    "# --- Test Case ---\n",
    "# Input shape: [Batch, KV_Heads, Seq_Len, Head_Dim]\n",
    "input_tensor = torch.randn(1, 2, 4, 8)\n",
    "num_repeats = 2\n",
    "\n",
    "output_tensor = repeat_kv(input_tensor, num_repeats)\n",
    "\n",
    "print(f\"Input shape:  {list(input_tensor.shape)}\")   # [1, 2, 4, 8]\n",
    "print(f\"Num repeats:  {num_repeats}\")\n",
    "print(f\"Output shape: {list(output_tensor.shape)}\")  # [1, 4, 4, 8]\n",
    "\n",
    "# Verification\n",
    "assert output_tensor.shape == (1, 4, 4, 8), \"Shape mismatch!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02188c7d",
   "metadata": {},
   "source": [
    "# PART 3: Implementing the GQA module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class GroupedQueryAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, num_kv_groups):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Ensure num_heads is divisible by num_kv_groups\n",
    "        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n",
    "        \n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.num_kv_groups = num_kv_groups\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.num_repeats = num_heads // num_kv_groups\n",
    "        \n",
    "        # Linear layers for Q, K, and V projections \n",
    "        self.W_q = nn.Linear(d_in, d_out, bias=False)\n",
    "        kv_dim = self.head_dim * num_kv_groups\n",
    "        self.W_k = nn.Linear(d_in, kv_dim, bias=False)\n",
    "        self.W_v = nn.Linear(d_in, kv_dim, bias=False)\n",
    "        \n",
    "        self.out_proj = nn.Linear(d_out, d_out, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # batch size, sequence length, and d_model (num_heads * head_dimensions)\n",
    "        B, T, C = x.shape\n",
    "        \n",
    "        # Project Input â†’ Q, K, V\n",
    "        # dot product with W_q, W_k, and W_v\n",
    "        q = self.W_q(x)\n",
    "        k = self.W_k(x)\n",
    "        v = self.W_v(x)\n",
    "        \n",
    "        # (B,T, H, d_h) to (B, H, T, d_h) \n",
    "        # where H in q  is H_q and H in k and v is H_kv\n",
    "        q = q.view(B, T, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        k = k.view(B, T, self.num_kv_groups, self.head_dim).permute(0, 2, 1, 3)\n",
    "        v = v.view(B, T, self.num_kv_groups, self.head_dim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        # Using the repeat_kv function to broadcast the head (now in dim = 1)\n",
    "        k = repeat_kv(k, self.num_repeats)\n",
    "        v = repeat_kv(v, self.num_repeats)\n",
    "        \n",
    "        # Scaled Dot-Product Attention\n",
    "        attn_scores = (q @ k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "    \n",
    "        context = attn_weights @ v\n",
    "        \n",
    "        # Concatenate and project output\n",
    "        # Permute back to (B, T, H, d_h) before reshaping to (B, T, d_out)\n",
    "        context = context.permute(0, 2, 1, 3).contiguous().view(B, T, self.d_out)\n",
    "        return self.out_proj(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26b1c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  [1, 16, 512]\n",
      "Output shape: [1, 16, 512]\n"
     ]
    }
   ],
   "source": [
    "# --- Test Case ---\n",
    "d_in = 512\n",
    "num_heads = 8\n",
    "num_kv_groups = 2\n",
    "gqa_module = GroupedQueryAttention(d_in, d_in, num_heads, num_kv_groups)\n",
    "\n",
    "# Pass random tensor (Batch=1, Seq=16, Dim=512)\n",
    "x = torch.randn(1, 16, d_in)\n",
    "\n",
    "# calls the  forward function\n",
    "output = gqa_module(x)\n",
    "\n",
    "print(f\"Input shape:  {list(x.shape)}\")\n",
    "print(f\"Output shape: {list(output.shape)}\") # Should match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b403ac",
   "metadata": {},
   "source": [
    "# PART 4: The Model Surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41960a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def convert_mha_to_gqa(mha_weight, groups):\n",
    "    \"\"\"\n",
    "    Converts an MHA Key/Value weight matrix to GQA using mean-pooling.\n",
    "    \n",
    "    Args:\n",
    "        mha_weight: Tensor of shape (D_in, D_out)\n",
    "        groups: Number of MHA heads to average into a single GQA head\n",
    "        \n",
    "    Returns:\n",
    "        Compressed tensor of shape (D_in, D_out / groups)\n",
    "    \"\"\"\n",
    "    d_in, d_out = mha_weight.shape\n",
    "    \n",
    "    \n",
    "    # We reshape to: (D_in, Num_GQA_Groups, Heads_per_Group, D_head)\n",
    "    # Reshape to identify individual heads and group them\n",
    "    # -1 automatically calculates the number of GQA groups based on the input\n",
    "    # this becomes (1, 2, 2) with input of (1,4)\n",
    "    x = mha_weight.view(d_in, -1, groups)\n",
    "    \n",
    "    # Calculate the mean within each group (dim=2)\n",
    "    # the dims become (d_in, num_groups)\n",
    "    gqa_weight = x.mean(dim=2)\n",
    "    \n",
    "    # Reshape back to a 2D matrix (D_in, D_out_compressed)\n",
    "    # -1 helps squash all the other dimensions to 1, in the case that d_head is not 1\n",
    "    # The new D_out is (original D_out / groups)\n",
    "    return gqa_weight.view(d_in, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bfd423a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original MHA weights: tensor([[1., 3., 5., 7.]])\n",
      "Compressed GQA weights: tensor([[2., 6.]])\n",
      "Verification Success: The dummy weights averaged correctly.\n"
     ]
    }
   ],
   "source": [
    "# --- Test Case Verification ---\n",
    "# Create a dummy weight matrix for H=4 heads, D_head=1 (Total D_out = 4)\n",
    "# Head 1 = 1s, Head 2 = 3s, Head 3 = 5s, Head 4 = 7s\n",
    "mha_weight = torch.tensor([[1.0, 3.0, 5.0, 7.0]])\n",
    "groups = 2 \n",
    "\n",
    "# Run conversion\n",
    "gqa_weight = convert_mha_to_gqa(mha_weight, groups)\n",
    "\n",
    "print(f\"Original MHA weights: {mha_weight}\")\n",
    "print(f\"Compressed GQA weights: {gqa_weight}\")\n",
    "\n",
    "# Proof of correctness:\n",
    "# Group 1 (Heads 1 & 2): Mean of 1 and 3 is 2.0\n",
    "# Group 2 (Heads 3 & 4): Mean of 5 and 7 is 6.0\n",
    "expected = torch.tensor([[2.0, 6.0]])\n",
    "assert torch.allclose(gqa_weight, expected), \"Mean-pooling calculation failed!\"\n",
    "print(\"Verification Success: The dummy weights averaged correctly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
